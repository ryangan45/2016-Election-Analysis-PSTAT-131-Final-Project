---
title: "Final Project"
author: "John Hwang and Bryan Tsan"
date: "12/9/2017"
output: pdf_document
---

```{r}
library(tidyverse)
library(tree)
library(plyr)
library(randomForest)
library(class)
library(rpart)
library(maptree)
library(ROCR)
library(ggplot2)
library(reshape2)
library(lattice)
```

```{r Reading/Cleaning Data}
d1 = read.csv("student-mat.csv")

d2 = read.csv("student-por.csv")


#checking how many students are taking both classes
# Left out paid because it is class specific (math vs portuguese)
data.source=merge(d1,d2,by=c("school","sex","age","address","famsize","Pstatus",
                            "Medu","Fedu","Mjob","Fjob","reason","nursery","internet",
                            "guardian","guardian","traveltime","studytime","failures",
                            "schoolsup","famsup","activities","higher","romantic",
                            "famrel","freetime","goout","Dalc","Walc","health","absences"))
print(nrow(data.source))

# Get rids of the 85 repeated students when the datasets are merged together
dataset = rbind(d1,d2)
dataset.clean = dataset %>% distinct(school,sex,age,address,famsize,Pstatus,
                Medu,Fedu,Mjob,Fjob,reason,guardian,
                traveltime,studytime,failures,schoolsup, famsup,activities,
                nursery,higher,internet,romantic,famrel,freetime,
                goout,Dalc,Walc,health,absences, .keep_all = TRUE)
```

```{r Creating Variables}
dataset.clean$avggrades <- rowMeans(cbind(dataset.clean$G1,dataset.clean$G2,dataset.clean$G3))

dataset.clean$GradePerc <- dataset.clean$avggrades/20

dataset.clean$GPA <- cut(dataset.clean$GradePerc, 
                        breaks=c(-1,0,seq(.59,1.09,by=.1)),
                        labels=c(0,0,1,2,3,4,4))

class(dataset.clean$GPA)

dataset.clean$Success <- ifelse(dataset.clean$GPA == 2 | 
                                dataset.clean$GPA == 3 |
                                dataset.clean$GPA == 4 ,1, 0)

dataset.clean <- dataset.clean %>%
  mutate(Success = factor(Success, levels=c(0,1), labels=c("Fail", "Success")))

#dataset.clean <- dataset.clean[c(-31:-36)]
```

```{r Pre-Model Testing}
set.seed(1)
calc_error_rate <- function(predicted.value, true.value){return(mean(true.value!=predicted.value))}

records <- matrix(NA, nrow=3, ncol=2)
colnames(records) <- c("train.error","test.error")
rownames(records) <- c("logistic","tree", "random forest")


test.indices <- sample(1:nrow(dataset.clean), 359)
data.train <- dataset.clean[-test.indices,]
data.test <- dataset.clean[test.indices,]

nfold = 10
folds <- seq.int(nrow(data.train)) %>%
  cut(breaks = nfold, labels=FALSE) %>%
    sample
```

```{r Logistic Regression}
set.seed(1)

# Predict on TEST set to get TEST ERROR RATE
glm.test = glm(data.test$Success~.,data=data.test[,1:30], family = binomial)
prob.testing = predict(glm.test, type="response")

Dis.test = data.test %>%
  mutate(predSuccess=as.factor(ifelse(prob.testing <= 0.5,"Fail","Success")))

data.test.table = table(pred=Dis.test$predSuccess, true=Dis.test$Success)
data.test.table

# Test error rate
test.error = 1-sum(diag(data.test.table))/sum(data.test.table)
test.error



# Predict on TRAIN set to get TRAINING ERROR RATE
glm.train = glm(data.train$Success~., data = data.train[,1:30], family = binomial)
prob.training = predict(glm.train, type="response")

Dis.train = data.train %>%
  mutate(predSuccess=as.factor(ifelse(prob.training<=0.5,"Fail","Success")))

data.train.table = table(pred=Dis.train$predSuccess, true=Dis.train$Success)
data.train.table

# Training error rate
training.error = 1-sum(diag(data.train.table))/sum(data.train.table)
training.error

records[1,1] = training.error
records[1,2] = test.error

```

## Tree
```{r Decision Tree}
set.seed(1)
datatree = tree(data.train$Success~., data = data.train[,1:30],
                 control=tree.control(nobs=nrow(data.train),minsize=5,mindev = 0.001))

cv = cv.tree(datatree, rand=folds, method = "misclass")
best.size.cv <- min(cv$size[cv$dev == min(cv$dev)])
# best.size.cv = 1, but because predict function does not run with a class singlenode, we use the next best size of 17
best.size.cv <- 17

datatree.vl = tree(data.test$Success~. , data = data.test[,1:30],
                 control=tree.control(nobs=nrow(data.test),minsize=5,mindev = 0.001))
datatree.pruned.vl = prune.misclass(datatree.vl, best.size.cv)

datatree.pruned = prune.misclass(datatree, best = best.size.cv)

#draw.tree(datatree.pruned, nodeinfo=TRUE)

# Predict on TRAIN set then finding misclassification error
pred.pt.tr = predict(datatree.pruned, data.train, type="class")
train.error.rate = calc_error_rate(pred.pt.tr, datatree.pruned$y)
train.error.rate 

# Predict on TEST set then finding misclassification error
pred.pt.vl = predict(datatree.pruned, data.test, type="class")
val.error.rate = calc_error_rate(pred.pt.vl, datatree.pruned.vl$y)
val.error.rate

records[2,1] <- train.error.rate
records[2,2] <- val.error.rate
```

```{r Random Forest}
set.seed(1)
datatree.rf <- randomForest(data.train$Success~., data=data.train[,1:30], ntree=500, importance=T)
train.rf= calc_error_rate(datatree.rf$predicted, datatree.rf$y)
train.rf

datatree.rf.vl <- randomForest(data.test$Success~., data=data.test[,1:30], ntree=500, importance=T)
test.rf = calc_error_rate(datatree.rf.vl$predicted, datatree.rf.vl$y)
test.rf 


records[3,1] = train.rf
records[3,2] = test.rf

```

```{r ROC CURVE}
set.seed(1)
# Logistic Regression
prob.training = predict(glm.train, data.test, type="response")
pred.glm = prediction(prob.training, data.test$Success)
perf.glm = performance(pred.glm, measure="tpr", x.measure="fpr")

# TREE
prob.training2 = predict(datatree.pruned, data.test, type="vector")[,2]
pred.tree = prediction(prob.training2, data.test$Success)
perf.tree = performance(pred.tree, measure="tpr", x.measure="fpr")

#Random Forest
prob.training3 = predict(datatree.rf,data.test,type="prob")[,2]
pred.rf = prediction(prob.training3, data.test$Success)
perf.rf = performance(pred.rf,measure="tpr",x.measure="fpr")

#Plotting ROC Curves
plot(perf.glm, col="red", lwd=3, main="ROC curve")
plot(perf.tree, col="blue", lwd=4,add = TRUE)
plot(perf.rf,col="green",lwd=5,add=TRUE)

abline(a=0,b=1,lwd=2,lty=2,col="gray")
legend(0,1, legend=c("GLM", "Tree", "Forest"), col=c("red", "blue", "green"), lty=1, cex=0.8, text.font=2)

auc.glm = performance(pred.glm, "auc")@y.values
auc.tree = performance(pred.tree, "auc")@y.values
auc.rf = performance(pred.rf, "auc")@y.values

print("AUC of GLM")
auc.glm
print("AUC of Decision Tree")
auc.tree
print("AUC of Random Forest")
auc.rf
```

```{r Best Model}
#Random Forest
varImpPlot(datatree.rf, main = "Importance of variables for datatree.rf", n.var = 10, type=1)
fit <- glm(dataset.clean$Success~.,data=dataset.clean[,1:30], family = binomial)
summary(fit)
```